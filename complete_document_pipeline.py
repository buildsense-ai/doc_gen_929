#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gauzæ–‡æ¡£Agent - å®Œæ•´æ–‡æ¡£ç”Ÿæˆé—­ç¯æµç¨‹

å®ç°ä»åˆå§‹æ–‡æ¡£ç”Ÿæˆåˆ°è´¨é‡è¯„ä¼°ã€ç« èŠ‚é‡æ–°ç”Ÿæˆã€æœ€ç»ˆæ–‡æ¡£åˆå¹¶çš„å®Œæ•´é—­ç¯æµç¨‹
"""

import os
import sys
import json
import time
from datetime import datetime
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from main import DocumentGenerationPipeline
    from Document_Agent.final_review_agent.document_reviewer import DocumentReviewer
    from Document_Agent.final_review_agent.regenerate_sections import DocumentRegenerator
    from Document_Agent.final_review_agent.json_merger import JSONDocumentMerger
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‚¨åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤ç¨‹åºï¼Œå¹¶å®‰è£…äº†æ‰€æœ‰ä¾èµ–ã€‚")
    sys.exit(1)


class CompleteDocumentPipeline:
    """
    å®Œæ•´æ–‡æ¡£ç”Ÿæˆé—­ç¯æµç¨‹
    
    å®ç°ä»¥ä¸‹å®Œæ•´æµç¨‹ï¼š
    1. åˆå§‹æ–‡æ¡£ç”Ÿæˆï¼ˆç»“æ„è§„åˆ’ â†’ èµ„æ–™æ£€ç´¢ â†’ å†…å®¹ç”Ÿæˆï¼‰
    2. æ–‡æ¡£è´¨é‡è¯„ä¼°ï¼ˆè¯†åˆ«å†—ä½™å†…å®¹å’Œé—®é¢˜ï¼‰
    3. ç« èŠ‚é‡æ–°ç”Ÿæˆï¼ˆåŸºäºè¯„ä¼°å»ºè®®ä¼˜åŒ–å†…å®¹ï¼‰
    4. æ™ºèƒ½æ–‡æ¡£åˆå¹¶ï¼ˆç”Ÿæˆæœ€ç»ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
    """
    
    def __init__(self):
        """åˆå§‹åŒ–å®Œæ•´æµæ°´çº¿"""
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–å®Œæ•´æ–‡æ¡£ç”Ÿæˆé—­ç¯ç³»ç»Ÿ...")
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.base_pipeline = DocumentGenerationPipeline()
        self.document_reviewer = DocumentReviewer()
        self.document_regenerator = DocumentRegenerator()
        # DocumentMergeréœ€è¦åœ¨ä½¿ç”¨æ—¶åˆå§‹åŒ–ï¼Œå› ä¸ºå®ƒéœ€è¦ç‰¹å®šçš„å‚æ•°
        
        print("âœ… å®Œæ•´é—­ç¯ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
    
    def generate_complete_document_with_optimization(self, 
                                                   user_query: str, 
                                                   project_name: str = "é»˜è®¤é¡¹ç›®", 
                                                   output_dir: str = "complete_outputs",
                                                   enable_regeneration: bool = True) -> Dict[str, Any]:
        """
        å®Œæ•´æ–‡æ¡£ç”Ÿæˆé—­ç¯æµç¨‹
        
        Args:
            user_query: ç”¨æˆ·éœ€æ±‚æè¿°
            project_name: é¡¹ç›®åç§°
            output_dir: è¾“å‡ºç›®å½•
            enable_regeneration: æ˜¯å¦å¯ç”¨ç« èŠ‚é‡æ–°ç”Ÿæˆå’Œåˆå¹¶
            
        Returns:
            Dict: åŒ…å«æ‰€æœ‰ç”Ÿæˆæ–‡ä»¶å’Œæµç¨‹ä¿¡æ¯çš„å­—å…¸
        """
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        print("ğŸš€ å¼€å§‹å®Œæ•´æ–‡æ¡£ç”Ÿæˆé—­ç¯æµç¨‹...")
        print("=" * 100)
        print(f"ğŸ“ ç”¨æˆ·éœ€æ±‚ï¼š{user_query}")
        print(f"ğŸ·ï¸ é¡¹ç›®åç§°ï¼š{project_name}")
        print(f"ğŸ”„ ç« èŠ‚ä¼˜åŒ–ï¼š{'å¯ç”¨' if enable_regeneration else 'ç¦ç”¨'}")
        print("=" * 100)
        
        total_start_time = time.time()
        result = {
            'timestamp': timestamp,
            'user_query': user_query,
            'project_name': project_name,
            'output_directory': output_dir,
            'enable_regeneration': enable_regeneration,
            'stages': {}
        }
        
        try:
            # ==================== é˜¶æ®µ1-3ï¼šåˆå§‹æ–‡æ¡£ç”Ÿæˆ ====================
            print("\nğŸ“‹ é˜¶æ®µ1-3ï¼šåˆå§‹æ–‡æ¡£ç”Ÿæˆï¼ˆç»“æ„è§„åˆ’ â†’ èµ„æ–™æ£€ç´¢ â†’ å†…å®¹ç”Ÿæˆï¼‰")
            stage1_start = time.time()
            
            # ä½¿ç”¨åŸºç¡€æµæ°´çº¿ç”Ÿæˆåˆå§‹æ–‡æ¡£ï¼ˆä¸åŒ…å«è´¨é‡è¯„ä¼°ï¼‰
            initial_result = self.base_pipeline.generate_document_without_evaluation(
                user_query=user_query,
                project_name=project_name,
                output_dir=output_dir
            )
            
            stage1_time = time.time() - stage1_start
            result['stages']['initial_generation'] = {
                'duration': stage1_time,
                'files': initial_result,
                'status': 'completed'
            }
            
            print(f"âœ… åˆå§‹æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼è€—æ—¶ï¼š{stage1_time:.1f}ç§’")
            print(f"   ğŸ“„ ç”Ÿæˆæ–‡æ¡£ï¼š{initial_result['final_document']}")
            
            # å¦‚æœç¦ç”¨é‡æ–°ç”Ÿæˆï¼Œç›´æ¥è¿”å›åˆå§‹ç»“æœ
            if not enable_regeneration:
                total_time = time.time() - total_start_time
                result['total_duration'] = total_time
                result['final_document'] = initial_result['final_document']
                result['optimization_applied'] = False
                
                print("\n" + "=" * 100)
                print("ğŸ‰ æ–‡æ¡£ç”Ÿæˆæµç¨‹å®Œæˆï¼ï¼ˆæœªå¯ç”¨ç« èŠ‚ä¼˜åŒ–ï¼‰")
                print(f"â±ï¸  æ€»è€—æ—¶ï¼š{total_time:.1f}ç§’")
                print("=" * 100)
                
                return result
            
            # ==================== é˜¶æ®µ4ï¼šæ–‡æ¡£è´¨é‡è¯„ä¼° ====================
            print("\nğŸ“Š é˜¶æ®µ4ï¼šæ–‡æ¡£è´¨é‡æ·±åº¦è¯„ä¼°")
            stage4_start = time.time()
            
            # è¯»å–ç”Ÿæˆçš„æ–‡æ¡£å†…å®¹
            with open(initial_result['final_document'], 'r', encoding='utf-8') as f:
                document_content = f.read()
            
            # è¿›è¡Œç®€åŒ–è´¨é‡åˆ†æï¼ˆç”¨äºé‡æ–°ç”Ÿæˆï¼‰
            document_title = os.path.basename(initial_result['final_document']).replace('.md', '')
            quality_issues = self.document_reviewer.analyze_document_simple(
                document_content=document_content,
                document_path=initial_result['final_document'],
                document_title=document_title
            )
            
            # ä¿å­˜è´¨é‡è¯„ä¼°ç»“æœåˆ°æ–‡ä»¶
            if quality_issues:
                analysis_file = self.document_reviewer.save_simple_analysis_result(
                    quality_issues=quality_issues,
                    document_title=document_title,
                    output_dir=output_dir
                )
                print(f"   ğŸ“„ è¯„ä¼°ç»“æœå·²ä¿å­˜ï¼š{analysis_file}")
            
            stage4_time = time.time() - stage4_start
            result['stages']['quality_evaluation'] = {
                'duration': stage4_time,
                'issues_found': len(quality_issues),
                'issues': quality_issues,
                'status': 'completed'
            }
            
            print(f"âœ… è´¨é‡è¯„ä¼°å®Œæˆï¼è€—æ—¶ï¼š{stage4_time:.1f}ç§’")
            print(f"   âš ï¸  å‘ç°é—®é¢˜ï¼š{len(quality_issues)} ä¸ªç« èŠ‚éœ€è¦ä¼˜åŒ–")
            
            # å¦‚æœæ²¡æœ‰å‘ç°é—®é¢˜ï¼Œç›´æ¥è¿”å›åŸæ–‡æ¡£
            if len(quality_issues) == 0:
                total_time = time.time() - total_start_time
                result['total_duration'] = total_time
                result['final_document'] = initial_result['final_document']
                result['optimization_applied'] = False
                
                print("\n" + "=" * 100)
                print("ğŸ‰ æ–‡æ¡£è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–ï¼")
                print(f"â±ï¸  æ€»è€—æ—¶ï¼š{total_time:.1f}ç§’")
                print("=" * 100)
                
                return result
            
            # ==================== é˜¶æ®µ5ï¼šç« èŠ‚é‡æ–°ç”Ÿæˆ ====================
            print("\nğŸ”„ é˜¶æ®µ5ï¼šåŸºäºè¯„ä¼°å»ºè®®é‡æ–°ç”Ÿæˆç« èŠ‚")
            stage5_start = time.time()
            
            # é¦–å…ˆä¿å­˜è´¨é‡é—®é¢˜åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_evaluation_file = os.path.join(output_dir, f"temp_evaluation_{timestamp}.json")
            with open(temp_evaluation_file, 'w', encoding='utf-8') as f:
                json.dump(quality_issues, f, ensure_ascii=False, indent=2)
            
            # é‡æ–°ç”Ÿæˆæœ‰é—®é¢˜çš„ç« èŠ‚
            regenerated_result = self.document_regenerator.regenerate_document_sections(
                evaluation_file=temp_evaluation_file,
                document_file=initial_result['final_document'],
                output_dir=os.path.join(output_dir, "regenerated_outputs")
            )
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_evaluation_file)
            except:
                pass
            
            stage5_time = time.time() - stage5_start
            result['stages']['section_regeneration'] = {
                'duration': stage5_time,
                'regenerated_sections': len(regenerated_result),
                'output_files': regenerated_result,
                'status': 'completed'
            }
            
            print(f"âœ… ç« èŠ‚é‡æ–°ç”Ÿæˆå®Œæˆï¼è€—æ—¶ï¼š{stage5_time:.1f}ç§’")
            print(f"   ğŸ”„ é‡æ–°ç”Ÿæˆï¼š{len(regenerated_result)} ä¸ªç« èŠ‚")
            
            # ==================== é˜¶æ®µ6ï¼šæ™ºèƒ½æ–‡æ¡£åˆå¹¶ ====================
            print("\nğŸ”— é˜¶æ®µ6ï¼šæ™ºèƒ½åˆå¹¶ç”Ÿæˆæœ€ç»ˆä¼˜åŒ–æ–‡æ¡£")
            stage6_start = time.time()
            
            # ä¿å­˜é‡æ–°ç”Ÿæˆçš„ç»“æœåˆ°JSONæ–‡ä»¶
            regenerated_json_path = os.path.join(output_dir, "regenerated_outputs", f"regenerated_sections_{timestamp}.json")
            os.makedirs(os.path.dirname(regenerated_json_path), exist_ok=True)
            with open(regenerated_json_path, 'w', encoding='utf-8') as f:
                json.dump(regenerated_result, f, ensure_ascii=False, indent=2)
            
            # è·å–åŸå§‹JSONæ–‡ä»¶è·¯å¾„
            original_json_path = initial_result.get('structured_document', '')
            if not original_json_path or not os.path.exists(original_json_path):
                print(f"âš ï¸ åŸå§‹JSONæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾: {original_json_path}")
                # å°è¯•ä»è¾“å‡ºç›®å½•ä¸­æŸ¥æ‰¾JSONæ–‡ä»¶
                for file in os.listdir(output_dir):
                    if file.endswith('.json') and 'ç”Ÿæˆæ–‡æ¡£çš„ä¾æ®' in file:
                        original_json_path = os.path.join(output_dir, file)
                        print(f"âœ“ æ‰¾åˆ°åŸå§‹JSONæ–‡ä»¶: {original_json_path}")
                        break
            
            # åˆå§‹åŒ–å¹¶ä½¿ç”¨JSONæ–‡æ¡£åˆå¹¶å™¨
            document_merger = JSONDocumentMerger(
                original_json_path=original_json_path,
                regenerated_json_path=regenerated_json_path
            )
            
            # åŠ è½½æ–‡ä»¶
            document_merger.load_original_json()
            document_merger.load_regenerated_sections()
            
            # åœ¨JSONå±‚é¢åˆå¹¶æ–‡æ¡£
            merged_json_data = document_merger.merge_json_documents()
            
            # ä¿å­˜åˆå¹¶åçš„JSONæ–‡æ¡£
            timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_name = os.path.splitext(os.path.basename(original_json_path))[0]
            merged_json_path = os.path.join(output_dir, f"merged_{base_name}_{timestamp_str}.json")
            final_merged_json_path = document_merger.save_merged_json(merged_json_data, merged_json_path)
            
            # è½¬æ¢ä¸ºMarkdownæ ¼å¼
            merged_md_path = os.path.join(output_dir, f"merged_{base_name}_{timestamp_str}.md")
            final_merged_path = document_merger.convert_to_markdown(merged_json_data, merged_md_path)
            
            # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
            document_merger.generate_summary_report(final_merged_json_path, final_merged_path)
            
            # æ„å»ºè¿”å›ç»“æœ
            merged_result = {
                'merged_document': final_merged_path,
                'summary_report': final_merged_path.replace('.md', '_summary.md'),
                'sections_replaced': len(regenerated_result)
            }
            
            stage6_time = time.time() - stage6_start
            result['stages']['document_merging'] = {
                'duration': stage6_time,
                'merged_document': merged_result['merged_document'],
                'summary_report': merged_result['summary_report'],
                'sections_replaced': merged_result.get('sections_replaced', 0),
                'status': 'completed'
            }
            
            print(f"âœ… æ–‡æ¡£åˆå¹¶å®Œæˆï¼è€—æ—¶ï¼š{stage6_time:.1f}ç§’")
            print(f"   ğŸ“„ æœ€ç»ˆæ–‡æ¡£ï¼š{merged_result['merged_document']}")
            print(f"   ğŸ“‹ æ‘˜è¦æŠ¥å‘Šï¼š{merged_result['summary_report']}")
            
            # ==================== æµç¨‹å®Œæˆ ====================
            total_time = time.time() - total_start_time
            result['total_duration'] = total_time
            result['final_document'] = merged_result['merged_document']
            result['optimization_applied'] = True
            result['summary_report'] = merged_result['summary_report']
            
            print("\n" + "=" * 100)
            print("ğŸ‰ å®Œæ•´æ–‡æ¡£ç”Ÿæˆé—­ç¯æµç¨‹å…¨éƒ¨å®Œæˆï¼")
            print(f"ğŸ“Š æµç¨‹ç»Ÿè®¡ï¼š")
            print(f"   ğŸ“‹ åˆå§‹ç”Ÿæˆï¼š{stage1_time:.1f}ç§’")
            print(f"   ğŸ“Š è´¨é‡è¯„ä¼°ï¼š{stage4_time:.1f}ç§’")
            print(f"   ğŸ”„ ç« èŠ‚é‡ç”Ÿï¼š{stage5_time:.1f}ç§’")
            print(f"   ğŸ”— æ–‡æ¡£åˆå¹¶ï¼š{stage6_time:.1f}ç§’")
            print(f"   â±ï¸  æ€»è€—æ—¶ï¼š{total_time:.1f}ç§’")
            print(f"   âœ¨ ä¼˜åŒ–ç« èŠ‚ï¼š{len(quality_issues)} ä¸ª")
            print("=" * 100)
            
            return result
            
        except Exception as e:
            print(f"âŒ å®Œæ•´æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            result['error'] = str(e)
            result['status'] = 'failed'
            raise

    
def run_complete_pipeline(user_query: str,
                          project_name: str = "é»˜è®¤é¡¹ç›®",
                          output_dir: str = "complete_outputs",
                          enable_regeneration: bool = True) -> Dict[str, Any]:
    """
    ä¸€é”®è¿è¡Œå››ä¸ªAgentçš„å®Œæ•´é—­ç¯æµç¨‹ï¼ˆç»“æ„â†’æ£€ç´¢â†’æˆæ–‡â†’è¯„å®¡â†’å†ç”Ÿâ†’åˆå¹¶ï¼‰ã€‚

    Args:
        user_query: æ–‡æ¡£ç”Ÿæˆéœ€æ±‚æè¿°
        project_name: é¡¹ç›®åç§°ï¼ˆç”¨äºæ£€ç´¢ä¸æ ‡è¯†ï¼‰
        output_dir: è¾“å‡ºç›®å½•
        enable_regeneration: æ˜¯å¦å¯ç”¨åŸºäºè¯„å®¡ç»“æœçš„ç« èŠ‚å†ç”Ÿæˆä¸åˆå¹¶

    Returns:
        Dict[str, Any]: åŒ…å«å„é˜¶æ®µè¾“å‡ºè·¯å¾„ä¸ç»Ÿè®¡ä¿¡æ¯çš„ç»“æœå­—å…¸ã€‚é¢å¤–åŒ…å«
        é”® `process_report`ï¼ˆæµç¨‹æŠ¥å‘Šè·¯å¾„ï¼‰ï¼Œä¾¿äºæº¯æºã€‚
    """
    pipeline = CompleteDocumentPipeline()
    result = pipeline.generate_complete_document_with_optimization(
        user_query=user_query,
        project_name=project_name,
        output_dir=output_dir,
        enable_regeneration=enable_regeneration,
    )

    # å¯é€‰ï¼šç”Ÿæˆæµç¨‹æŠ¥å‘Š
    try:
        report_path = pipeline.generate_process_report(result)
        result['process_report'] = report_path
    except Exception:
        # æŠ¥å‘Šç”Ÿæˆå¤±è´¥ä¸é˜»æ–­ä¸»æµç¨‹
        pass

    return result
    
    def generate_process_report(self, result: Dict[str, Any], output_path: str = None) -> str:
        """
        ç”Ÿæˆæµç¨‹æŠ¥å‘Š
        
        Args:
            result: æµç¨‹æ‰§è¡Œç»“æœ
            output_path: æŠ¥å‘Šè¾“å‡ºè·¯å¾„
            
        Returns:
            str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            output_path = os.path.join(
                result['output_directory'], 
                f"complete_process_report_{result['timestamp']}.md"
            )
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        report_content = f"""# å®Œæ•´æ–‡æ¡£ç”Ÿæˆé—­ç¯æµç¨‹æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {timestamp}
**ç”¨æˆ·éœ€æ±‚**: {result['user_query']}
**é¡¹ç›®åç§°**: {result['project_name']}
**ç« èŠ‚ä¼˜åŒ–**: {'å¯ç”¨' if result['enable_regeneration'] else 'ç¦ç”¨'}
**æ€»è€—æ—¶**: {result.get('total_duration', 0):.1f}ç§’

## æµç¨‹æ¦‚è§ˆ

æœ¬æ¬¡æ–‡æ¡£ç”Ÿæˆé‡‡ç”¨äº†å®Œæ•´çš„é—­ç¯ä¼˜åŒ–æµç¨‹ï¼š

1. **åˆå§‹æ–‡æ¡£ç”Ÿæˆ** - ç»“æ„è§„åˆ’ã€èµ„æ–™æ£€ç´¢ã€å†…å®¹ç”Ÿæˆ
2. **æ–‡æ¡£è´¨é‡è¯„ä¼°** - è¯†åˆ«å†—ä½™å†…å®¹å’Œæ”¹è¿›ç‚¹
3. **ç« èŠ‚é‡æ–°ç”Ÿæˆ** - åŸºäºè¯„ä¼°å»ºè®®ä¼˜åŒ–å†…å®¹
4. **æ™ºèƒ½æ–‡æ¡£åˆå¹¶** - ç”Ÿæˆæœ€ç»ˆä¼˜åŒ–ç‰ˆæœ¬

## å„é˜¶æ®µè¯¦æƒ…

"""
        
        # æ·»åŠ å„é˜¶æ®µè¯¦æƒ…
        for stage_name, stage_info in result.get('stages', {}).items():
            stage_title = {
                'initial_generation': 'åˆå§‹æ–‡æ¡£ç”Ÿæˆ',
                'quality_evaluation': 'æ–‡æ¡£è´¨é‡è¯„ä¼°',
                'section_regeneration': 'ç« èŠ‚é‡æ–°ç”Ÿæˆ',
                'document_merging': 'æ™ºèƒ½æ–‡æ¡£åˆå¹¶'
            }.get(stage_name, stage_name)
            
            report_content += f"### {stage_title}\n\n"
            report_content += f"- **è€—æ—¶**: {stage_info.get('duration', 0):.1f}ç§’\n"
            report_content += f"- **çŠ¶æ€**: {stage_info.get('status', 'unknown')}\n"
            
            if stage_name == 'quality_evaluation':
                report_content += f"- **å‘ç°é—®é¢˜**: {stage_info.get('issues_found', 0)} ä¸ªç« èŠ‚éœ€è¦ä¼˜åŒ–\n"
            elif stage_name == 'section_regeneration':
                report_content += f"- **é‡æ–°ç”Ÿæˆ**: {stage_info.get('regenerated_sections', 0)} ä¸ªç« èŠ‚\n"
            elif stage_name == 'document_merging':
                report_content += f"- **æ›¿æ¢ç« èŠ‚**: {stage_info.get('sections_replaced', 0)} ä¸ª\n"
            
            report_content += "\n"
        
        # æ·»åŠ æœ€ç»ˆç»“æœ
        report_content += f"""## æœ€ç»ˆç»“æœ

- **æœ€ç»ˆæ–‡æ¡£**: {result.get('final_document', 'N/A')}
- **ä¼˜åŒ–åº”ç”¨**: {'æ˜¯' if result.get('optimization_applied', False) else 'å¦'}
- **è¾“å‡ºç›®å½•**: {result.get('output_directory', 'N/A')}

## è´¨é‡æå‡

é€šè¿‡å®Œæ•´çš„é—­ç¯ä¼˜åŒ–æµç¨‹ï¼Œæœ¬æ¬¡ç”Ÿæˆçš„æ–‡æ¡£åœ¨ä»¥ä¸‹æ–¹é¢å¾—åˆ°äº†æå‡ï¼š

1. **å†…å®¹è´¨é‡** - æ¶ˆé™¤äº†å†—ä½™è¡¨è¾¾ï¼Œæé«˜äº†å†…å®¹ç²¾ç‚¼åº¦
2. **é€»è¾‘ç»“æ„** - ä¼˜åŒ–äº†ç« èŠ‚é—´çš„é€»è¾‘å…³ç³»å’Œè¡”æ¥
3. **ä¸“ä¸šæ€§** - å¢å¼ºäº†ä¸“ä¸šæœ¯è¯­ä½¿ç”¨å’Œè¡¨è¾¾å‡†ç¡®æ€§
4. **å¯è¯»æ€§** - æ”¹å–„äº†æ–‡æ¡£çš„æ•´ä½“å¯è¯»æ€§å’Œç”¨æˆ·ä½“éªŒ

---

*æœ¬æŠ¥å‘Šç”±Gauzæ–‡æ¡£Agentå®Œæ•´é—­ç¯ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""
        
        # ä¿å­˜æŠ¥å‘Š
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return output_path


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå®Œæ•´é—­ç¯æµç¨‹"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    Gauzæ–‡æ¡£Agent - å®Œæ•´æ–‡æ¡£ç”Ÿæˆé—­ç¯ç³»ç»Ÿ                        â•‘
â•‘                                                                              â•‘
â•‘  ğŸ”„ å®ç°ä»åˆå§‹ç”Ÿæˆåˆ°è´¨é‡è¯„ä¼°ã€ç« èŠ‚ä¼˜åŒ–ã€æ™ºèƒ½åˆå¹¶çš„å®Œæ•´é—­ç¯æµç¨‹                  â•‘
â•‘  ğŸ“ æ”¯æŒæ™ºèƒ½è¯†åˆ«é—®é¢˜ç« èŠ‚å¹¶è‡ªåŠ¨é‡æ–°ç”Ÿæˆä¼˜åŒ–å†…å®¹                                â•‘
â•‘  ğŸš€ æä¾›ä¸“ä¸šçº§æ–‡æ¡£è´¨é‡æ§åˆ¶å’ŒæŒç»­æ”¹è¿›èƒ½åŠ›                                      â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    # åˆ›å»ºå®Œæ•´æµæ°´çº¿
    pipeline = CompleteDocumentPipeline()
    
    # ç¤ºä¾‹ï¼šç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„æ–‡æ¡£
    user_query = "ç¼–å†™åŒ»çµå¤åº™æ–‡ç‰©ä¿æŠ¤é¡¹ç›®çš„å¯è¡Œæ€§ç ”ç©¶æŠ¥å‘Š"
    project_name = "åŒ»çµå¤åº™"
    
    try:
        # æ‰§è¡Œå®Œæ•´é—­ç¯æµç¨‹
        result = pipeline.generate_complete_document_with_optimization(
            user_query=user_query,
            project_name=project_name,
            output_dir="complete_demo_outputs",
            enable_regeneration=True
        )
        
        # ç”Ÿæˆæµç¨‹æŠ¥å‘Š
        report_path = pipeline.generate_process_report(result)
        print(f"\nğŸ“‹ æµç¨‹æŠ¥å‘Šå·²ç”Ÿæˆï¼š{report_path}")
        
        print(f"\nğŸ“ æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{result['output_directory']}")
        print(f"ğŸ“„ æœ€ç»ˆä¼˜åŒ–æ–‡æ¡£ï¼š{result['final_document']}")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºæ‰§è¡Œå¤±è´¥: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())