#!/usr/bin/env python3
"""
ç®€åŒ–æ–‡æ¡£ç”Ÿæˆå™¨ - ä¸»ç¨‹åºï¼ˆæ™ºèƒ½é€Ÿç‡æ§åˆ¶å¢å¼ºç‰ˆï¼‰

åŠŸèƒ½ï¼š
- è¯»å–JSONæ–‡ä»¶ï¼ˆç”Ÿæˆæ–‡æ¡£çš„ä¾æ®.jsonï¼‰
- é›†æˆé«˜çº§æ™ºèƒ½é€Ÿç‡æ§åˆ¶ç³»ç»Ÿ
- åªç”Ÿæˆæ­£æ–‡å†…å®¹ï¼ˆä¸åŒ…å«æ ‡é¢˜ï¼‰
- è¾“å‡ºå®Œæ•´ç‰ˆmarkdownæ–‡æ¡£ï¼ˆæ— é¦–è¡Œç¼©è¿›ï¼‰
- å®æ—¶æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–å»ºè®®
"""

import json
import os
import sys
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Any, Tuple
from datetime import datetime
import logging

# ç¡®ä¿å¯ä»¥å¯¼å…¥æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from Document_Agent.content_generator_agent.simple_agent import SimpleContentGeneratorAgent
from clients.openrouter_client import OpenRouterClient
from config.settings import setup_logging, get_concurrency_manager, SmartConcurrencyManager


class EnhancedMainDocumentGenerator:
    """ä¸»æ–‡æ¡£ç”Ÿæˆå™¨ - é›†æˆæ™ºèƒ½é€Ÿç‡æ§åˆ¶ç³»ç»Ÿ"""
    
    def __init__(self, concurrency_manager: SmartConcurrencyManager = None):
        # è®¾ç½®æ—¥å¿—
        setup_logging()
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯å’ŒAgent
        self.llm_client = OpenRouterClient()
        self.agent = SimpleContentGeneratorAgent(self.llm_client)
        
        # æ™ºèƒ½å¹¶å‘ç®¡ç†å™¨
        self.concurrency_manager = concurrency_manager or get_concurrency_manager()
        self.max_workers = self.concurrency_manager.get_max_workers('content_generator_agent')
        
        # æ™ºèƒ½é€Ÿç‡æ§åˆ¶å™¨
        self.rate_limiter = self.concurrency_manager.get_rate_limiter('content_generator_agent')
        self.has_smart_control = self.concurrency_manager.has_smart_rate_control('content_generator_agent')
        
        # å…¼å®¹æ€§ï¼šä¿ç•™ä¼ ç»Ÿé€Ÿç‡æ§åˆ¶ä½œä¸ºåå¤‡
        self.rate_limit_delay = self.concurrency_manager.get_rate_limit_delay('content_generator_agent')
        self.last_request_time = 0
        self.request_lock = threading.Lock()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.generation_stats = {
            'total_sections': 0,
            'completed_sections': 0,
            'failed_sections': 0,
            'total_generation_time': 0.0,
            'avg_quality_score': 0.0,
            'start_time': None,
            'end_time': None
        }
        
        status_msg = f"æ™ºèƒ½é€Ÿç‡æ§åˆ¶: {'å·²å¯ç”¨' if self.has_smart_control else 'ä¼ ç»Ÿæ¨¡å¼'}"
        self.logger.info(f"EnhancedMainDocumentGenerator åˆå§‹åŒ–å®Œæˆï¼Œå¹¶å‘çº¿ç¨‹æ•°: {self.max_workers}, {status_msg}")

    def set_max_workers(self, max_workers: int):
        """åŠ¨æ€è®¾ç½®æœ€å¤§çº¿ç¨‹æ•°"""
        self.max_workers = max_workers
        self.concurrency_manager.set_max_workers('content_generator_agent', max_workers)
        self.logger.info(f"ContentGeneratorAgent çº¿ç¨‹æ•°å·²æ›´æ–°ä¸º: {max_workers}")

    def get_max_workers(self) -> int:
        """è·å–å½“å‰æœ€å¤§çº¿ç¨‹æ•°"""
        return self.max_workers

    def set_rate_limit_delay(self, delay: float):
        """åŠ¨æ€è®¾ç½®é€Ÿç‡é™åˆ¶å»¶è¿Ÿ"""
        self.rate_limit_delay = delay
        self.concurrency_manager.set_rate_limit_delay(delay, 'content_generator_agent')
        self.logger.info(f"ContentGeneratorAgent é€Ÿç‡é™åˆ¶å·²æ›´æ–°ä¸º: {delay}ç§’")

    def get_rate_limit_delay(self) -> float:
        """è·å–å½“å‰é€Ÿç‡é™åˆ¶å»¶è¿Ÿ"""
        if self.has_smart_control:
            return self.rate_limiter.get_delay()
        return self.rate_limit_delay

    def generate_document(self, json_file_path: str = "ç¬¬äºŒagentçš„è¾“å‡º.json") -> str:
        """
        ç”Ÿæˆæ–‡æ¡£ï¼ˆæ™ºèƒ½é€Ÿç‡æ§åˆ¶å¢å¼ºç‰ˆï¼‰
        
        Args:
            json_file_path: JSONæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: å®Œæ•´ç‰ˆæ–‡æ¡£è·¯å¾„
        """
        
        print("ğŸš€ å¼€å§‹ç”Ÿæˆæ–‡æ¡£ï¼ˆæ™ºèƒ½é€Ÿç‡æ§åˆ¶å¢å¼ºç‰ˆï¼‰...")
        print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {json_file_path}")
        print(f"ğŸ”§ å¹¶è¡Œçº¿ç¨‹: {self.max_workers}")
        
        if self.has_smart_control:
            print(f"ğŸ§  æ™ºèƒ½é€Ÿç‡æ§åˆ¶: å·²å¯ç”¨ï¼Œç›®æ ‡æˆåŠŸç‡ {self.rate_limiter.agent_config['target_success_rate']:.0%}")
        else:
            print(f"â±ï¸  ä¼ ç»Ÿé€Ÿç‡é™åˆ¶: {self.rate_limit_delay}ç§’/è¯·æ±‚")
            
        print("=" * 60)
        
        # åˆå§‹åŒ–ç»Ÿè®¡
        self.generation_stats['start_time'] = datetime.now()
        
        # 1. æ£€æŸ¥æ–‡ä»¶
        if not os.path.exists(json_file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        
        # 2. è¯»å–JSON
        with open(json_file_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
        
        # 3. å¹¶è¡Œç”Ÿæˆå†…å®¹ï¼ˆæ™ºèƒ½é€Ÿç‡æ§åˆ¶ç‰ˆï¼‰
        updated_json = self._generate_content_parallel_smart(json_data)
        
        # 4. ä¿å­˜JSONå’Œç”Ÿæˆmarkdown
        result_path = self._save_results(updated_json)
        
        # 5. è¾“å‡ºæ€§èƒ½æŠ¥å‘Š
        self._print_performance_report()
        
        return result_path
    
    def _generate_content_parallel_smart(self, json_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¹¶è¡Œç”Ÿæˆå†…å®¹ï¼ˆæ™ºèƒ½é€Ÿç‡æ§åˆ¶ç‰ˆï¼‰
        """
        
        updated_json = json.loads(json.dumps(json_data))
        tasks = []

        # é€’å½’æ”¶é›†æ‰€æœ‰å¶å­èŠ‚ç‚¹ä»»åŠ¡ï¼ˆæ— å­èŠ‚ç‚¹æˆ–å­èŠ‚ç‚¹ä¸ºç©ºï¼‰
        def collect_leaf_tasks(title_idx: int, nodes: List[Dict[str, Any]], path_prefix: List[int]) -> None:
            if not isinstance(nodes, list):
                return
            for idx, node in enumerate(nodes):
                if not isinstance(node, dict):
                    continue
                subsections = node.get('subsections', [])
                has_children = isinstance(subsections, list) and len(subsections) > 0
                current_path = path_prefix + [idx]
                if not has_children and 'subtitle' in node:
                    tasks.append({
                        'title_idx': title_idx,
                        'path': current_path,  # ä»sectionså¼€å§‹çš„ç´¢å¼•è·¯å¾„
                        'subtitle': node.get('subtitle', ''),
                        'how_to_write': node.get('how_to_write', ''),
                        'retrieved_text': node.get('retrieved_text', []),
                        'retrieved_image': node.get('retrieved_image', []),
                        'retrieved_table': node.get('retrieved_table', []),
                        'retrieved_web': node.get('retrieved_web', [])
                    })
                else:
                    collect_leaf_tasks(title_idx, subsections or [], current_path)

        for title_idx, title_part in enumerate(updated_json.get('report_guide', [])):
            collect_leaf_tasks(title_idx, title_part.get('sections', []), [])
        
        total_tasks = len(tasks)
        completed_tasks = 0
        self.generation_stats['total_sections'] = total_tasks
        
        print(f"ğŸ“Š å¼€å§‹å¹¶è¡Œå¤„ç† {total_tasks} ä¸ªä»»åŠ¡...")
        
        # å¹¶è¡Œæ‰§è¡Œï¼ˆæ™ºèƒ½é€Ÿç‡æ§åˆ¶ç‰ˆï¼‰
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {
                executor.submit(self._generate_single_section_smart, task): task
                for task in tasks
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_task):
                task = future_to_task[future]
                try:
                    result = future.result()
                    
                    # æ›´æ–°JSONï¼ˆæ ¹æ®è·¯å¾„å®šä½å¶å­èŠ‚ç‚¹ï¼‰
                    title_idx = task['title_idx']
                    path = task['path']
                    node_cursor = updated_json['report_guide'][title_idx].get('sections', [])
                    target_node = None
                    for depth, idx in enumerate(path):
                        if depth == len(path) - 1:
                            target_node = node_cursor[idx]
                        else:
                            node_cursor = node_cursor[idx].get('subsections', [])
                    if isinstance(target_node, dict):
                        target_node['generated_content'] = result['content']
                        target_node['quality_score'] = result['quality_score']
                        target_node['word_count'] = result['word_count']
                        target_node['generation_time'] = result['generation_time']
                    
                    completed_tasks += 1
                    self.generation_stats['completed_sections'] = completed_tasks
                    progress = (completed_tasks / total_tasks) * 100
                    
                    # è·å–å½“å‰å»¶è¿ŸçŠ¶æ€
                    if self.has_smart_control:
                        current_delay = self.rate_limiter.current_delay
                        performance_level = self.rate_limiter._assess_performance_level()
                        status_icon = "ğŸš€" if performance_level == "excellent" else "âš¡" if performance_level == "good" else "âš ï¸"
                    else:
                        current_delay = self.rate_limit_delay
                        status_icon = "ğŸ”„"
                    
                    print(f"{status_icon} [{completed_tasks:2d}/{total_tasks}] {progress:5.1f}% | {task['subtitle'][:25]:<25} | {result['word_count']:4d}å­— | è´¨é‡:{result['quality_score']:.2f} | å»¶è¿Ÿ:{current_delay:.1f}s")
                    
                except Exception as e:
                    completed_tasks += 1
                    self.generation_stats['failed_sections'] += 1
                    
                    # è®°å½•å¤±è´¥åˆ°æ™ºèƒ½é€Ÿç‡æ§åˆ¶å™¨
                    if self.has_smart_control:
                        self.concurrency_manager.record_api_request(
                            agent_name='content_generator_agent',
                            success=False,
                            error_type='unknown'
                        )
                    
                    print(f"âŒ [{completed_tasks:2d}/{total_tasks}] å¤±è´¥ | {task['subtitle'][:25]:<25} | é”™è¯¯: {e}")
        
        print("ğŸ‰ å¹¶è¡Œç”Ÿæˆå®Œæˆ!")
        self.generation_stats['end_time'] = datetime.now()
        return updated_json
    
    def _generate_single_section_smart(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå•ä¸ªç« èŠ‚ï¼ˆæ™ºèƒ½é€Ÿç‡æ§åˆ¶ç‰ˆï¼‰"""
        
        start_time = time.time()
        
        # æ™ºèƒ½é€Ÿç‡æ§åˆ¶
        if self.has_smart_control:
            # ä½¿ç”¨æ™ºèƒ½é€Ÿç‡æ§åˆ¶å™¨è·å–åŠ¨æ€å»¶è¿Ÿ
            delay = self.rate_limiter.get_delay()
            if delay > 0:
                time.sleep(delay)
        else:
            # å…¼å®¹æ€§ï¼šä½¿ç”¨ä¼ ç»Ÿé€Ÿç‡æ§åˆ¶
            with self.request_lock:
                current_time = time.time()
                time_since_last = current_time - self.last_request_time
                
                if time_since_last < self.rate_limit_delay:
                    sleep_time = self.rate_limit_delay - time_since_last
                    time.sleep(sleep_time)
                
                self.last_request_time = time.time()
        
        # æ‰§è¡Œå†…å®¹ç”Ÿæˆ
        try:
            generation_start = time.time()
            result = self.agent.generate_content_from_json(
                task['subtitle'],
                task['how_to_write'],
                task['retrieved_text'],
                task['retrieved_image'],
                task['retrieved_table'],
                task['retrieved_web']
            )
            generation_time = time.time() - generation_start
            
            # è®°å½•æˆåŠŸåˆ°æ™ºèƒ½é€Ÿç‡æ§åˆ¶å™¨
            if self.has_smart_control:
                self.concurrency_manager.record_api_request(
                    agent_name='content_generator_agent',
                    success=True,
                    response_time=generation_time
                )
            
            return result
            
        except Exception as e:
            generation_time = time.time() - generation_start if 'generation_start' in locals() else 0
            
            # æ™ºèƒ½é”™è¯¯åˆ†ç±»å’Œè®°å½•
            if self.has_smart_control:
                error_type = self._classify_error(str(e))
                self.concurrency_manager.record_api_request(
                    agent_name='content_generator_agent',
                    success=False,
                    response_time=generation_time,
                    error_type=error_type
                )
            
            raise e
    
    def _classify_error(self, error_message: str) -> str:
        """æ™ºèƒ½é”™è¯¯åˆ†ç±»"""
        error_msg = error_message.lower()
        
        if 'rate limit' in error_msg or '429' in error_msg:
            return 'rate_limit'
        elif 'timeout' in error_msg:
            return 'timeout'
        elif 'network' in error_msg or 'connection' in error_msg:
            return 'network'
        elif '5' in error_msg[:2]:  # 5xx errors
            return 'server_error'
        elif '4' in error_msg[:2]:  # 4xx errors
            return 'client_error'
        else:
            return 'unknown'
    
    def _save_results(self, updated_json: Dict[str, Any]) -> str:
        """ä¿å­˜ç»“æœæ–‡ä»¶"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜JSON
        json_path = f"ç”Ÿæˆæ–‡æ¡£çš„ä¾æ®_å®Œæˆ_{timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(updated_json, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆmarkdown
        full_md_path = f"å®Œæ•´ç‰ˆæ–‡æ¡£_{timestamp}.md"
        
        # å®Œæ•´ç‰ˆ
        full_content = self._convert_to_markdown(updated_json)
        with open(full_md_path, 'w', encoding='utf-8') as f:
            f.write(full_content)
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = self._get_stats(updated_json)
        
        print("=" * 60)
        print("ğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
        print(f"   æ€»ç« èŠ‚æ•°: {stats['total_sections']}")
        print(f"   å®Œæˆç« èŠ‚: {stats['completed_sections']}")
        print(f"   å¤±è´¥ç« èŠ‚: {self.generation_stats['failed_sections']}")
        print(f"   æ€»å­—æ•°: {stats['total_words']:,}")
        print(f"   å¹³å‡è´¨é‡åˆ†: {stats['average_quality']:.3f}")
        print("=" * 60)
        print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   JSON: {json_path}")
        print(f"   Markdown: {full_md_path}")
        print("=" * 60)
        
        # è¿”å›JSONæ–‡ä»¶è·¯å¾„ï¼Œä»¥ä¾¿åç»­çš„é‡æ–°ç”ŸæˆåŠŸèƒ½ä½¿ç”¨
        return json_path
    
    def _print_performance_report(self):
        """æ‰“å°æ€§èƒ½æŠ¥å‘Š"""
        if not self.has_smart_control:
            print("â„¹ï¸  æ™ºèƒ½é€Ÿç‡æ§åˆ¶æœªå¯ç”¨ï¼Œæ— è¯¦ç»†æ€§èƒ½æŠ¥å‘Š")
            return
        
        print("\n" + "="*60)
        print("ğŸ“ˆ æ™ºèƒ½é€Ÿç‡æ§åˆ¶æ€§èƒ½æŠ¥å‘Š")
        print("="*60)
        
        # è·å–æ€§èƒ½æŠ¥å‘Š
        report = self.concurrency_manager.get_performance_report('content_generator_agent')
        
        if 'error' in report:
            print(f"âš ï¸  {report['error']}")
            return
        
        # åŸºæœ¬æ€§èƒ½æŒ‡æ ‡
        print(f"ğŸ¯ ç›®æ ‡æˆåŠŸç‡: {report['target_success_rate']:.0%}")
        print(f"ğŸ“Š å®é™…æˆåŠŸç‡: {report['recent_success_rate']:.1%}")
        print(f"â±ï¸  å½“å‰å»¶è¿Ÿ: {report['current_delay']:.2f}ç§’")
        print(f"ğŸ”„ è‡ªé€‚åº”å› å­: {report['adaptive_factor']:.2f}")
        print(f"ğŸ“ˆ æ€§èƒ½ç­‰çº§: {report['performance_level']}")
        print(f"ğŸ“‰ è¶‹åŠ¿: {report['trend']}")
        
        # é”™è¯¯ç»Ÿè®¡
        if report['error_breakdown']:
            print(f"\nğŸš¨ é”™è¯¯åˆ†å¸ƒ:")
            for error_type, count in report['error_breakdown'].items():
                print(f"   {error_type}: {count}æ¬¡")
        
        # ä¼˜åŒ–å»ºè®®
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for suggestion in report['recommendations']:
            print(f"   â€¢ {suggestion}")
        
        print("="*60)

    def get_comprehensive_performance_report(self) -> Dict[str, Any]:
        """è·å–ç»¼åˆæ€§èƒ½æŠ¥å‘Š"""
        base_report = {
            'generation_stats': self.generation_stats.copy(),
            'system_config': {
                'max_workers': self.max_workers,
                'has_smart_control': self.has_smart_control,
                'rate_limit_delay': self.rate_limit_delay
            }
        }
        
        if self.has_smart_control:
            smart_report = self.concurrency_manager.get_performance_report('content_generator_agent')
            base_report['smart_rate_control'] = smart_report
        
        return base_report

    def _convert_to_markdown(self, json_data: Dict[str, Any]) -> str:
        """
        è½¬æ¢ä¸ºmarkdownæ ¼å¼
        """
        
        markdown_lines = []
        report_guide = json_data.get('report_guide', [])

        def render_node(node: Dict[str, Any], level: int) -> None:
            subtitle = node.get('subtitle', '')
            header_level = min(max(level, 2), 6)
            markdown_lines.append(f"{'#' * header_level} {subtitle}")
            markdown_lines.append("")

            generated_content = node.get('generated_content', '')
            retrieved_table = node.get('retrieved_table', [])
            retrieved_image = node.get('retrieved_image', [])
            children = node.get('subsections', []) or []

            if generated_content:
                content = self._format_content(generated_content)
                #æºå¸¦å›¾ç‰‡å’Œè¡¨æ ¼
                # content_with_media = self._append_tables_and_images(content, retrieved_table, retrieved_image)
                # markdown_lines.append(content_with_media)
                #ä¸æºå¸¦å›¾ç‰‡å’Œè¡¨æ ¼
                markdown_lines.append(content)
                markdown_lines.append("")
            else:
                # ä»…åœ¨å¶å­èŠ‚ç‚¹ç¼ºå°‘æ­£æ–‡æ—¶æ˜¾ç¤ºå ä½ç¬¦ï¼›éå¶å­èŠ‚ç‚¹è·³è¿‡å ä½ç¬¦
                if not children:
                    markdown_lines.append("*[å†…å®¹æœªç”Ÿæˆ]*")
                    markdown_lines.append("")

            for child in children:
                render_node(child, level + 1)

        for title_section in report_guide:
            title = title_section.get('title', '')
            sections = title_section.get('sections', [])

            markdown_lines.append(f"# {title}")
            markdown_lines.append("")

            for section in sections:
                render_node(section, 2)

        return "\n".join(markdown_lines)
    
    def _format_content(self, content: str) -> str:
        """
        å¯¹æ­£æ–‡å†…å®¹è¿›è¡Œæ ¼å¼åŒ–ï¼ˆæ— ç¼©è¿›ï¼‰
        """
        
        if not content:
            return content
        
        # ç›´æ¥è¿”å›åŸå†…å®¹ï¼Œä¸è¿›è¡Œç¼©è¿›å¤„ç†
        return content
    
    def _append_tables_and_images(self, content: str, retrieved_table: list, retrieved_image: list) -> str:
        """
        åœ¨ç”Ÿæˆçš„ç« èŠ‚å†…å®¹åé¢æ’å…¥è¡¨æ ¼å’Œå›¾ç‰‡
        
        Args:
            content: ç”Ÿæˆçš„ç« èŠ‚å†…å®¹
            retrieved_table: è¡¨æ ¼æ£€ç´¢ç»“æœåˆ—è¡¨
            retrieved_image: å›¾ç‰‡æ£€ç´¢ç»“æœåˆ—è¡¨
            
        Returns:
            str: åŒ…å«è¡¨æ ¼å’Œå›¾ç‰‡çš„å®Œæ•´å†…å®¹
        """
        final_content = content
        
        # æ·»åŠ è¡¨æ ¼ - ä½¿ç”¨ä¸‰çº§æ ‡é¢˜
        if retrieved_table:
            final_content += "\n\n### ç›¸å…³è¡¨æ ¼èµ„æ–™\n"
            for i, table_item in enumerate(retrieved_table, 1):
                table_content = table_item.get('content', str(table_item))
                table_source = table_item.get('source', 'æœªçŸ¥æ¥æº')
                final_content += f"\n**è¡¨æ ¼{i}** (æ¥æº: {table_source})\n\n{table_content}\n"
        
        # æ·»åŠ å›¾ç‰‡ - ä½¿ç”¨ä¸‰çº§æ ‡é¢˜å’Œmarkdownå›¾ç‰‡è¯­æ³•ï¼Œå¹¶å»é‡
        if retrieved_image:
            final_content += "\n\n### ç›¸å…³å›¾ç‰‡èµ„æ–™\n"
            
            # æ ¹æ®URLå»é‡å›¾ç‰‡
            seen_urls = set()
            unique_images = []
            for image_item in retrieved_image:
                image_path = image_item.get('path', 'æ— è·¯å¾„')
                if image_path and image_path != 'æ— è·¯å¾„' and image_path not in seen_urls:
                    seen_urls.add(image_path)
                    unique_images.append(image_item)
                elif image_path == 'æ— è·¯å¾„':  # ä¿ç•™æ²¡æœ‰è·¯å¾„çš„å›¾ç‰‡é¡¹
                    unique_images.append(image_item)
            
            for i, image_item in enumerate(unique_images, 1):
                image_desc = image_item.get('content', image_item.get('description', f'æ£€ç´¢åˆ°çš„ç›¸å…³å›¾ç‰‡ {i}'))
                image_path = image_item.get('path', 'æ— è·¯å¾„')
                image_source = image_item.get('source', 'æœªçŸ¥æ¥æº')
                
                # é™åˆ¶å›¾ç‰‡æè¿°é•¿åº¦åˆ°100å­—ç¬¦ä»¥å†…
                if len(image_desc) > 100:
                    image_desc = image_desc[:97] + "..."
                
                # ä½¿ç”¨æ ‡å‡†markdownå›¾ç‰‡è¯­æ³•
                if image_path and image_path != 'æ— è·¯å¾„':
                    final_content += f"\n![{image_desc}]({image_path})\n*å›¾ç‰‡æ¥æº: {image_source}*\n"
                else:
                    final_content += f"\n**å›¾ç‰‡{i}** (æ¥æº: {image_source})  \næè¿°: {image_desc}  \n*è·¯å¾„æœªæä¾›*\n"
        
        return final_content
    
    def _get_stats(self, json_data: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        
        stats = {
            'total_sections': 0,  # ç»Ÿè®¡å¶å­èŠ‚ç‚¹
            'completed_sections': 0,  # å®Œæˆçš„å¶å­èŠ‚ç‚¹
            'total_words': 0,
            'average_quality': 0.0
        }
        
        report_guide = json_data.get('report_guide', [])
        quality_scores = []

        def accumulate_leaf_stats(nodes: List[Dict[str, Any]]):
            if not isinstance(nodes, list):
                return
            for node in nodes:
                if not isinstance(node, dict):
                    continue
                subs = node.get('subsections', [])
                has_children = isinstance(subs, list) and len(subs) > 0
                if not has_children and node.get('subtitle'):
                    stats['total_sections'] += 1
                    if 'generated_content' in node:
                        stats['completed_sections'] += 1
                        stats['total_words'] += node.get('word_count', 0)
                        quality_scores.append(node.get('quality_score', 0.0))
                if has_children:
                    accumulate_leaf_stats(subs)

        for title_section in report_guide:
            accumulate_leaf_stats(title_section.get('sections', []))
        
        if quality_scores:
            stats['average_quality'] = sum(quality_scores) / len(quality_scores)
        
        return stats


def main():
    """ä¸»å‡½æ•°"""
    
    try:
        # åˆ›å»ºç”Ÿæˆå™¨
        generator = EnhancedMainDocumentGenerator()
        
        # ç”Ÿæˆæ–‡æ¡£
        full_path = generator.generate_document()
        
        print("ğŸ‰ æ–‡æ¡£ç”Ÿæˆå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())